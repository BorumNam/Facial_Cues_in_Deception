{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dcbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind_from_stats, t\n",
    "import math\n",
    "\n",
    "# Define data paths\n",
    "police_path = 'F:/FacialExpression/Police/TimeSeriesAnalysisResults/MicroExpression'\n",
    "stim_path = 'F:/FacialExpression/3rdYear_stim/TimeSeriesAnalysisResults/EC_control'\n",
    "mock_path = 'F:/FacialExpression/3rdYear/TimeSeriesAnalysisResults/EC_control'\n",
    "\n",
    "police_output_path = 'F:/FacialExpression/Police/TimeSeriesAnalysisResults/StatisticalAnalysis'\n",
    "stim_output_path = 'F:/FacialExpression/3rdYear_stim/TimeSeriesAnalysisResults/StatisticalAnalysis'\n",
    "mock_output_path = 'F:/FacialExpression/3rdYear/TimeSeriesAnalysisResults/StatisticalAnalysis'\n",
    "\n",
    "# Output file details\n",
    "output_file = 'police_ME_AU06_11frame_statistics.csv'\n",
    "feature_type = 'ME'\n",
    "path = police_path\n",
    "output_path = police_output_path\n",
    "\n",
    "feat_idx = 4\n",
    "frame_idx = 10\n",
    "\n",
    "T_total_result = []\n",
    "F_total_result = []\n",
    "\n",
    "# Load data and collect relevant values\n",
    "for f in sorted(os.listdir(path)):\n",
    "    df = pd.read_csv(os.path.join(path, f))\n",
    "    df = df.to_numpy()\n",
    "    df = df[:, 1:]\n",
    "    if f.split('.')[0].split('_')[-1] == 'T':\n",
    "        T_total_result.append(df[frame_idx, feat_idx])\n",
    "    elif f.split('.')[0].split('_')[-1] == 'F':\n",
    "        F_total_result.append(df[frame_idx, feat_idx])\n",
    "\n",
    "# Initialize statistics dictionary and confidence interval\n",
    "statistics = {}\n",
    "confidence_interval = 0.95  # Confidence interval (95%)\n",
    "\n",
    "# Calculate statistics for observations A and B\n",
    "observation_A = T_total_result\n",
    "observation_B = F_total_result\n",
    "observation_statistics = {}\n",
    "\n",
    "# 1. Independent samples t-test between groups A and B\n",
    "truth_mean = np.mean(T_total_result)\n",
    "truth_std = np.std(T_total_result)\n",
    "truth_sample_size = len(T_total_result)\n",
    "\n",
    "deception_mean = np.mean(F_total_result)\n",
    "deception_std = np.std(F_total_result)\n",
    "deception_sample_size = len(F_total_result)\n",
    "\n",
    "t_statistic, p_value = ttest_ind_from_stats(\n",
    "    truth_mean, truth_std, truth_sample_size,\n",
    "    deception_mean, deception_std, deception_sample_size\n",
    ")\n",
    "observation_statistics['t-test'] = {'t-statistic': t_statistic, 'p-value': p_value}\n",
    "\n",
    "# 2. Calculate Cohen's d effect size\n",
    "def cohen_d(a, b):\n",
    "    pooled_std = math.sqrt((np.std(a, ddof=1) ** 2 + np.std(b, ddof=1) ** 2) / 2)\n",
    "    return abs(np.mean(a) - np.mean(b)) / pooled_std\n",
    "\n",
    "if len(observation_A) == len(observation_B):\n",
    "    effect_size = cohen_d(observation_A, observation_B)\n",
    "    observation_statistics[\"Cohen's d\"] = effect_size\n",
    "else:\n",
    "    n1 = len(observation_A)\n",
    "    n2 = len(observation_B)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * np.var(observation_A) + (n2 - 1) * np.var(observation_B)) / (n1 + n2 - 2))\n",
    "    effect_size = (np.mean(observation_A) - np.mean(observation_B)) / pooled_std\n",
    "    observation_statistics[\"Cohen's d (Adjusted)\"] = effect_size\n",
    "\n",
    "# 3. Calculate mean difference\n",
    "mean_diff = np.mean(observation_A) - np.mean(observation_B)\n",
    "observation_statistics['Mean Difference'] = mean_diff\n",
    "\n",
    "# 4. Calculate standard error of the mean\n",
    "s1 = np.std(observation_A, ddof=1)\n",
    "s2 = np.std(observation_B, ddof=1)\n",
    "n1 = len(observation_A)\n",
    "n2 = len(observation_B)\n",
    "sem = np.sqrt((s1**2 / n1) + (s2**2 / n2))\n",
    "observation_statistics['Standard Error of the Mean'] = sem\n",
    "\n",
    "# 5. Calculate means of groups A and B\n",
    "mean_A = np.mean(observation_A)\n",
    "mean_B = np.mean(observation_B)\n",
    "observation_statistics['Mean'] = {'A_group': mean_A, 'B_group': mean_B}\n",
    "\n",
    "# 6. Calculate t-value for groups A and B (when sample sizes are different)\n",
    "if len(observation_A) != len(observation_B):\n",
    "    var1 = np.var(observation_A, ddof=1)\n",
    "    var2 = np.var(observation_B, ddof=1)\n",
    "    n1 = len(observation_A)\n",
    "    n2 = len(observation_B)\n",
    "    dof = ((var1 / n1 + var2 / n2) ** 2) / (((var1 / n1) ** 2) / (n1 - 1) + ((var2 / n2) ** 2) / (n2 - 1))\n",
    "\n",
    "    if np.isinf(dof):\n",
    "        dof = np.inf\n",
    "\n",
    "    t_critical = t.ppf(confidence_interval, dof)\n",
    "    std_error_diff = np.sqrt((var1 / n1) + (var2 / n2))\n",
    "    mean_diff_interval = t_critical * std_error_diff\n",
    "    observation_statistics['t-value'] = mean_diff_interval\n",
    "    observation_statistics['Degrees of Freedom'] = dof\n",
    "\n",
    "# 7. Calculate confidence interval for groups A and B (when sample sizes are different)\n",
    "t_critical = t.ppf(confidence_interval, min(len(observation_A), len(observation_B)) - 1)\n",
    "std_err_A = np.std(observation_A, ddof=1) / np.sqrt(len(observation_A))\n",
    "std_err_B = np.std(observation_B, ddof=1) / np.sqrt(len(observation_B))\n",
    "mean_diff_interval = t_critical * np.sqrt(std_err_A**2 + std_err_B**2)\n",
    "mean_A_minus_mean_B = np.mean(observation_A) - np.mean(observation_B)\n",
    "observation_statistics['Confidence Interval'] = {'lower': mean_A_minus_mean_B - mean_diff_interval,\n",
    "                                                 'upper': mean_A_minus_mean_B + mean_diff_interval}\n",
    "\n",
    "# Add observation statistics to the main statistics dictionary\n",
    "statistics[f'Observation'] = observation_statistics\n",
    "\n",
    "# Convert statistics to a DataFrame and save as a CSV file\n",
    "df = pd.DataFrame.from_dict(statistics, orient='columns')\n",
    "output_dir = os.path.join(output_path, feature_type)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "df.to_csv(os.path.join(output_dir, output_file), index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
